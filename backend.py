#!/usr/bin/env python
# coding: utf-8

import os
import json
import getpass

import requests
import chromadb
from chromadb import PersistentClient
from dotenv import load_dotenv

from langchain.vectorstores import Chroma
from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings
from langchain_mistralai.chat_models import ChatMistralAI
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.messages import HumanMessage
from langchain_core.prompts import (
    ChatPromptTemplate, PromptTemplate, PipelinePromptTemplate
)
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langchain import hub


# Load environment variables from .env file

load_dotenv()

LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
MODEL_NAME = os.getenv("MODEL_NAME")

# Building a Retrieval Augmented Generation (RAG) Chatbot

get_ipython().system('pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph')
get_ipython().system('pip install -qU langchain-mistralai')
get_ipython().system('pip install -qU langchain-chroma')
get_ipython().system('pip install python-dotenv')

# Chat model initialization
llm = ChatMistralAI(
    mistral_api_key=MISTRAL_API_KEY,
    model=MODEL_NAME,
    streaming=True,
    temperature=0.6
)

# Embeddings model
embeddings = MistralAIEmbeddings(model="mistral-embed")

# 1ï¸âƒ£ Connect to the existing ChromaDB instance
db_path = "./RAG/final_chroma_db"
collection_name = "final_vector_store_collection"

client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)

# 2ï¸âƒ£ Load stored embeddings from ChromaDB
stored_data = collection.get()

# 3ï¸âƒ£ Check how many embeddings are loaded
num_loaded = len(stored_data["ids"])

# ğŸ”„ Recharger le vector store depuis la base de donnÃ©es ChromaDB
vector_store = Chroma(
    persist_directory=db_path,
    collection_name=collection_name,
    embedding_function=embeddings
)

# LLM Prompt-Engineering

prompt_principal = ChatPromptTemplate.from_template(
    """
    Tu es **Crystal Bot**, un assistant intelligent d'orientation professionnelle.
    Tu dois fournir des rÃ©ponses basÃ©es sur les informations rÃ©cupÃ©rÃ©es.
    
    Ton objectif est d'aider chaque utilisateur Ã  **clarifier son avenir** en lui proposant **des conseils sur-mesure et motivants**.

    **Contexte pertinent issu de la base de connaissances :** 
    {context}
    
    â¤ **Adapte-toi Ã  lâ€™utilisateur** : si indÃ©cis, propose des pistes dâ€™exploration.
    â¤ **Si comparaison de plusieurs options**, aide-le Ã  peser le pour et le contre.
    â¤ **Propose une rÃ©ponse fluide, naturelle et pas trop longue**, qui ne se contente pas dâ€™une liste figÃ©e, mais qui Ã©tablit un dialogue et donne des solutions plus large.
    """
)

topic_prompt = PromptTemplate.from_template(
    """
    Analyse la question suivante et identifie le ou les domaines principaux auxquels elle appartient.

    Question: {input}

    RÃ©ponds en listant **un ou plusieurs domaines** parmi les suivants (sÃ©parÃ©s par une virgule) :
    - "Informatique et NumÃ©rique"
    - "Sciences et IngÃ©nierie"
    - "SantÃ© et MÃ©decine"
    - "Droit et Sciences Politiques"
    - "Ã‰conomie et Gestion"
    - "Sciences Sociales et Psychologie"
    - "Arts, Design et Culture"
    - "Lettres et Langues"
    - "Sciences de l'Ã‰ducation"
    - "Communication et Journalisme"
    - "Tourisme, HÃ´tellerie et Restauration"
    - "Environnement et DÃ©veloppement Durable"
    - "Sport et ActivitÃ© Physique"
    - "Architecture et Urbanisme"
    - "Agronomie et Agroalimentaire"

    Si aucun domaine nâ€™est clair, rÃ©ponds uniquement par "Autre".

    Domaines identifiÃ©s :
    """
)

intent_prompt = PromptTemplate.from_template(
    """
    Analyse la question suivante et identifie lâ€™intention principale de lâ€™utilisateur :

    Question: {input}

    RÃ©ponds par lâ€™une ou plusieurs des options suivantes :
    - "MÃ©tiers"
    - "Formations"
    - "Salaire"
    - "Offres d'emploi"
    - "Parcoursup"
    - "Autre"

    Intention dÃ©tectÃ©e :
    """
)

chatbot_prompt = PromptTemplate.from_template(
    """
    
    Je suis **Crystal Bot**, ton conseiller d'orientation professionnelle. ğŸ”®âœ¨  
    
    L'utilisateur a demandÃ© : {input}.
    Domaine dÃ©tectÃ© : {topic} (cachÃ© Ã  l'utilisateur)
    Intention dÃ©tectÃ©e : {intent} (cachÃ© Ã  l'utilisateur)
    
  â¤ **Si l'intention est "MÃ©tiers"** :
        - Propose des **mÃ©tiers adaptÃ©s** au profil de lâ€™utilisateur en allant au-delÃ  des Ã©vidences.   
        - Explique **les missions, conditions de travail et dÃ©bouchÃ©s** en tâ€™adaptant Ã  la curiositÃ© de lâ€™utilisateur.  
        - **Nâ€™hÃ©site pas Ã  raconter une anecdote ou une tendance actuelle, personnalise la rÃ©ponse** pour rendre la rÃ©ponse plus vivante et personnalisÃ©e.  
        - **Fournis une vision inspirante et dynamique**, et pas seulement une simple liste de mÃ©tiers.

    â¤ **Si l'intention est "Formations"** :
        - PrÃ©sente des **formations pertinentes** mais **ajoute des alternatives originales** (double cursus, parcours atypiques).
        - DÃ©cris les options de maniÃ¨re dynamique : **BTS, Licence, Master, Ã©coles spÃ©cialisÃ©es, mais aussi MOOC et certifications**.  
        - **Varie les approches selon la question de lâ€™utilisateur**, sans donner toujours la mÃªme liste figÃ©e.
        - Rassure lâ€™utilisateur en expliquant que *sa motivation est un facteur clÃ©*. *Donne lui des conseils*
        - **Nâ€™hÃ©site pas Ã  raconter une anecdote ou une tendance actuelle, personnalise la rÃ©ponse** pour rendre la rÃ©ponse plus vivante et personnalisÃ©e. 
        - Si pertinent propose Ã  l'utilisateur de visiter des salons pour en savoir plus sur les formations. 

    â¤ **Si l'intention est "Salaire"** :
        - Donne **un aperÃ§u dÃ©taillÃ© des salaires**, mais va au-delÃ  des chiffres standards en ajoutant **les tendances du marchÃ©**.  
        - Explique **les diffÃ©rences selon lâ€™expÃ©rience, le secteur, et la localisation**.  
        - **Si pertinent, parle des avantages indirects** (avantages en nature, perspectives dâ€™Ã©volution, travail Ã  lâ€™international).  
         - **Nâ€™hÃ©site pas Ã  raconter une anecdote ou une tendance actuelle, personnalise la rÃ©ponse** pour rendre la rÃ©ponse plus vivante et personnalisÃ©e.  

    â¤ **Si l'intention est "Offres d'emploi"** :
        - **DÃ©cris le marchÃ© actuel** du secteur concernÃ© : quelles entreprises recrutent ? Quelles compÃ©tences sont recherchÃ©es ?
        - Donne **des conseils personnalisÃ©s** pour optimiser les candidatures, en fonction du domaine visÃ©.
        - **Propose une approche proactive** : comment crÃ©er des opportunitÃ©s, rÃ©seauter efficacement ou se dÃ©marquer ?  
         - **Nâ€™hÃ©site pas Ã  raconter une anecdote ou une tendance actuelle, personnalise la rÃ©ponse** pour rendre la rÃ©ponse plus vivante et personnalisÃ©e.  

    â¤ **Si l'intention est "Parcoursup"** :
        - **Explique Parcoursup en tâ€™adaptant au profil de lâ€™utilisateur** (lycÃ©en stressÃ©, Ã©tudiant en rÃ©orientationâ€¦).
        - Fournis **des conseils concrets pour rÃ©ussir son dossier** et Ã©viter les piÃ¨ges.  
        - Fournis **des conseils concrets pour rÃ©ussir la lettre de motivation** et se distinguer des autres candidats. 
        - Si pertinent, parle **des alternatives Ã  Parcoursup** (Ã©coles privÃ©es, Ã©tudes Ã  lâ€™Ã©tranger, admissions parallÃ¨les).  
    

    â¤ **Si l'intention est "Autre"** :
        - **InterprÃ¨te la demande de lâ€™utilisateur avec souplesse** et propose une rÃ©ponse originale.  
        - Si possible, **ouvre la discussion sur des idÃ©es nouvelles** en fonction de son profil.
        - **Demande lui plus de prÃ©cisions sur ce qu'il souhaite apprendre ou approfondir** en terme professionnel ou de formation.
         
    """
)

closing_prompt = PromptTemplate.from_template(
    """
    Jâ€™espÃ¨re que cette rÃ©ponse **tâ€™a aidÃ© Ã  y voir plus clair !** ğŸ”®  
    **As-tu dâ€™autres questions ?** Je suis lÃ  pour explorer toutes les possibilitÃ©s avec toi.  
    """
)

# Setting up conversation memory

memory = MemorySaver()
workflow = StateGraph(state_schema=MessagesState)

def call_model(state: MessagesState):
    """Appelle le modÃ¨le avec historique de conversation"""
    response = llm.invoke(state["messages"])
    return {"messages": response}

workflow.add_edge(START, "model")
workflow.add_node("model", call_model)
chatbot = workflow.compile(checkpointer=memory)

# Creating the retrieval chain with LangChain

def build_retrieval_chain(vector_store, llm, k=5):
    """
    Build a retrieval chain using a given vector store and LLM
    
    Parameters:
        - vector_store: The vector store containing document embeddings
        - llm: The language model to generate responses
        - k: Number of most relevant document chunks to retrieve (default is 5)
    
    Returns:
        - retrieval_chain: A LangChain retrieval chain object.
    """
    # Create a retriever from the vector store
    retriever = vector_store.as_retriever(search_kwargs={"k": k})
    
    # Load a pre-defined prompt template for retrieval-based Q&A
    retrieval_chat_prompt = hub.pull("langchain-ai/retrieval-qa-chat")
    
    # Create a document combination chain
    combine_docs_chain = create_stuff_documents_chain(llm, retrieval_chat_prompt)
    
    # Create and return the retrieval chain
    return create_retrieval_chain(retriever, combine_docs_chain)

def retrieve_and_format_context(user_query, vector_store, llm):
    """Retrieve documents from vector store and format the context"""
    retrieval_chain = build_retrieval_chain(vector_store, llm)
    retrieved_docs = retrieval_chain.invoke({"input": user_query})

    documents = retrieved_docs["context"]

    formatted_context = "\n".join([doc.page_content for doc in documents])
    sources = [doc.metadata.get("source", "Unknown source") for doc in documents]

    return formatted_context, sources

# Building a full ChatBot response

def generate_response(user_query, vector_store, llm):
    """Generate an optimized response with CrystalBot and keep the history"""

    context, sources = retrieve_and_format_context(user_query, vector_store, llm)
    
    global conversation_history  # Utilisation d'une variable distincte pour stocker les messages

    # Charger l'historique des messages de maniÃ¨re locale
    past_messages = conversation_history if 'conversation_history' in globals() else []  

    # **ğŸ”¹ Ã‰tape 1 : DÃ©tection du domaine / topic**
    topic_output = topic_prompt.format(input=user_query)

    # **ğŸ”¹ Ã‰tape 2 : DÃ©tection de lâ€™intention utilisateur**
    intent_output = intent_prompt.format(input=user_query)
    if not intent_output:
        intent_output = "Autre"

    # **ğŸ”¹ Ã‰tape 3 : GÃ©nÃ©ration de la rÃ©ponse principale**
    chatbot_prompt_hidden = chatbot_prompt.format(
        input=user_query, 
        topic=topic_output, 
        intent=intent_output,
        context=context,
    )

    chatbot_output = chatbot_prompt_hidden.replace(topic_output, "").replace(intent_output, "")

    # **ğŸ”¹ Ã‰tape 4 : GÃ©nÃ©ration des suggestions dâ€™exploration selon lâ€™intention dÃ©tectÃ©e**
    exploration_suggestions = ""

    if "MÃ©tiers" in intent_output:
        exploration_suggestions += """
        **ğŸŒ Pour aller plus loin :**  
        - ğŸ” **DÃ©couvre des mÃ©tiers similaires** via des plateformes comme Onisep ou Studyrama.  
        - ğŸ­ **Participe Ã  des salons professionnels** et rencontres avec des experts du domaine.  
        - ğŸ‘¥ **Ã‰change avec des professionnels** sur LinkedIn ou lors dâ€™Ã©vÃ©nements.  
        """

    if "Formations" in intent_output or "Parcoursup" in intent_output:
        exploration_suggestions += """
        **ğŸ“š Pour approfondir ton parcours :**  
        - ğŸ¤ **DÃ©couvre les parcours dâ€™anciens Ã©tudiants** via des tÃ©moignages en ligne.  
        - ğŸ” **Explore les formations en alternance** et internationales.  
        - ğŸ« **Assiste aux journÃ©es portes ouvertes** des Ã©coles et universitÃ©s.  
        """

    if "Salaire" in intent_output:
        exploration_suggestions += """
        **ğŸ’° Pour mieux comprendre les salaires et Ã©volutions de carriÃ¨re :**  
        - ğŸ“Š **Consulte des Ã©tudes de rÃ©munÃ©ration** sur Glassdoor et lâ€™APEC.  
        - ğŸ“ˆ **Analyse les Ã©volutions de carriÃ¨re possibles** en fonction de ton secteur.  
        """

    if "Offres d'emploi" in intent_output:
        exploration_suggestions += """
        **ğŸ“ Pour trouver des opportunitÃ©s professionnelles :**  
        - ğŸ” **Consulte des plateformes spÃ©cialisÃ©es** comme Indeed ou PÃ´le Emploi.  
        - ğŸ“© **Optimise ton CV et ta lettre de motivation** pour te dÃ©marquer.  
        """

    if "Les deux" in intent_output:
        exploration_suggestions += """
        **ğŸŒŸ Pour lier formations et mÃ©tiers :**  
        - ğŸ“š **DÃ©couvre les formations qui recrutent le plus**.  
        - ğŸ‘€ **Explore les tendances de recrutement dans ton secteur**.  
        """

    if "Autre" in intent_output:
        exploration_suggestions += """
        **ğŸ” Explorons dâ€™autres pistes !**  
        - ğŸ¤” **PrÃ©cise un peu plus ta demande**, veux-tu parler de reconversion, dâ€™entrepreneuriat, dâ€™Ã©tudes Ã  lâ€™Ã©tranger ?  
        - ğŸ’¡ **Inspiration** : Parfois, explorer dâ€™autres secteurs peut ouvrir des portes inattendues.  
        - ğŸ” **DÃ©couvre des parcours inspirants** : interviews, confÃ©rences, podcasts sur des choix de carriÃ¨re atypiques.  
        """

    # **ğŸ”¹ Ã‰tape 5 : Conclusion dynamique**
    closing_output = closing_prompt.format()

    # âœ… **Ajout dâ€™une introduction engageante pour la toute premiÃ¨re rÃ©ponse**
    intro_message = f"""
    Bonjour ! ğŸ˜Š  

    Je suis **Crystal Bot**, ton conseiller d'orientation professionnelle. ğŸ”®âœ¨  
    Mon objectif est de **tâ€™aider Ã  clarifier ton avenir** en te proposant des pistes adaptÃ©es et personnalisÃ©es.  
    Voici quelques idÃ©es et conseils pour tâ€™aider Ã  avancer :  
    """

    # âœ… **CrÃ©ation du message final Ã  envoyer au modÃ¨le**
    final_prompt = f"""
    {intro_message}  

    **ğŸ’¡ Recommandation de Crystal Bot :**  
    {chatbot_output}  

    {exploration_suggestions}  

    {closing_output}  
    """

    # âœ… **Ajout du message dans l'historique**
    messages = past_messages + [HumanMessage(content=final_prompt)]

    # âœ… **Envoi de la requÃªte complÃ¨te au modÃ¨le**
    response = llm.invoke(messages)

    # âœ… **Mise Ã  jour de l'historique de la conversation**
    conversation_history = messages + [response]

    return {
        "response": response.content,
        "sources": sources
    }

def refine_response(chatbot_output, user_query, llm):
    """Improve clarity and precision of response with LLM"""
    refinement_prompt = f"""
    AmÃ©liore la rÃ©ponse suivante en la rendant plus prÃ©cise et engageante :
    Contexte : {user_query}
    RÃ©ponse initiale : {chatbot_output}
    RÃ©ponse amÃ©liorÃ©e :
    """

    refined_response = llm.invoke([HumanMessage(content=refinement_prompt)]).content

    return refined_response